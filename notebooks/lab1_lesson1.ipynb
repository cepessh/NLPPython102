{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 1 - Lesson 1: Dataset exploration and Zipf\n",
        "\n",
        "**What we use**\n",
        "- `datasets` to download and slice a small dataset subset.\n",
        "- `Counter` to count tokens and build a frequency dictionary.\n",
        "- `matplotlib` to plot a Zipf curve on log-log axes.\n",
        "\n",
        "**Goals**\n",
        "- Load a small dataset subset with `datasets`.\n",
        "- Compute token frequencies and plot Zipf on log-log axes.\n",
        "- Inspect samples and dataset fields."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acbd6c12",
      "metadata": {},
      "source": [
        "**Notes to keep in mind**\n",
        "- More word types, shorter lemmas, and a larger highest rank often indicate a more morphologically rich language.\n",
        "- A shallower Zipf slope often indicates a more morphologically rich language.\n",
        "- The straightness of a Zipf plot is not related to morphology.\n",
        "- If the same surface word appears with different lemmas in counts, it is ambiguous.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c8cb07d",
      "metadata": {},
      "source": [
        "## Step 1: Load and inspect the dataset\n",
        "We start by loading a dataset from the Hugging Face Hub and selecting a small subset\n",
        "The Hugging Face Hub is an online repository of datasets and models; `datasets.load_dataset` downloads from the Hub when needed.\n",
        "so the notebook runs quickly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from datasets import load_dataset\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset choice\n",
        "# Option A: name = 'ag_news', text_field = 'text'\n",
        "# Option B: name = 'wikitext', config = 'wikitext-2-raw-v1', text_field = 'text'\n",
        "name = 'ag_news'\n",
        "config = None\n",
        "text_field = 'text'\n",
        "\n",
        "if config:\n",
        "    ds = load_dataset(name, config, split='train')\n",
        "else:\n",
        "    ds = load_dataset(name, split='train')\n",
        "\n",
        "subset = ds.select(range(2000))\n",
        "print(subset.features)\n",
        "print(subset[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Practice A: Create two subsets\n",
        "Create two different slices of the dataset and compare their sizes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Create two non-overlapping subsets from ds\n",
        "# Hint: use ds.select(range(start, end))\n",
        "# Hint: keep the subsets the same size for comparison\n",
        "# TODO: print sizes with len(subset_a) and len(subset_b)\n",
        "\n",
        "# Write your code below\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(3):\n",
        "    print('---')\n",
        "    print(subset[i][text_field])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Tokenize and count\n",
        "We use a simple whitespace tokenizer to keep the logic clear.\n",
        "Then we count tokens and types with `Counter`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tokenize_whitespace(text):\n",
        "    return text.lower().split()\n",
        "\n",
        "def get_token_counts(texts):\n",
        "    # TODO: implement token counting with Counter\n",
        "    counts = Counter()\n",
        "    for t in texts:\n",
        "        counts.update(tokenize_whitespace(t))\n",
        "    return counts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "texts = [ex[text_field] for ex in subset if ex[text_field].strip()]\n",
        "counts = get_token_counts(texts)\n",
        "total_tokens = sum(counts.values())\n",
        "total_types = len(counts)\n",
        "\n",
        "print('tokens:', total_tokens)\n",
        "print('types:', total_types)\n",
        "print('top-20:', counts.most_common(20))\n",
        "\n",
        "assert sum(counts.values()) == total_tokens\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Practice B: Extra frequency stats\n",
        "Compute type/token ratio and average whitespace length.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Type/token ratio** is the number of unique word types divided by the total number of tokens.\n",
        "It is a rough proxy for lexical diversity in a sample.\n",
        "\n",
        "**Average whitespace length** is the average number of whitespace-separated tokens per sentence.\n",
        "It is a simple length measure before any advanced tokenization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def avg_whitespace_len(texts):\n",
        "    # TODO: compute average whitespace token length\n",
        "    # Hint: lengths = [len(tokenize_whitespace(t)) for t in texts]\n",
        "    # Hint: avoid division by zero with max(len(lengths), 1)\n",
        "    raise NotImplementedError\n",
        "\n",
        "# TODO: compute type_token_ratio and avg_len\n",
        "# Hint: type_token_ratio = total_types / total_tokens\n",
        "# TODO: print the results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Plot Zipf\n",
        "We first plot on linear axes to see why the long tail is hard to read,\n",
        "then switch to log-log axes for a clearer Zipf pattern.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3a: Linear scale (less informative)\n",
        "We first plot the same data on linear axes to see why the long tail is hard to read.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "freqs = sorted(counts.values(), reverse=True)\n",
        "ranks = range(1, len(freqs) + 1)\n",
        "\n",
        "# Linear-scale version (for contrast)\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(ranks, freqs)\n",
        "plt.xlabel('rank')\n",
        "plt.ylabel('frequency')\n",
        "plt.title('Zipf plot (linear scale)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3b: Log-log scale (more informative)\n",
        "Log-log axes compress the long tail and make Zipf behavior visible.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "freqs = sorted(counts.values(), reverse=True)\n",
        "ranks = range(1, len(freqs) + 1)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.loglog(ranks, freqs)\n",
        "plt.xlabel('rank')\n",
        "plt.ylabel('frequency')\n",
        "plt.title('Zipf plot')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Practice C: Compare Zipf plots\n",
        "Plot Zipf curves for two different subsets on the same axes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: build texts_a and texts_b from subset_a and subset_b\n",
        "# Hint: filter out empty strings with .strip()\n",
        "# TODO: compute counts and frequency lists for both subsets\n",
        "# Hint: counts = get_token_counts(texts)\n",
        "# TODO: plot both Zipf curves on the same axes with labels\n",
        "# Hint: use plt.loglog for each and plt.legend()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8c1bd2d",
      "metadata": {},
      "source": [
        "**Homework**\n",
        "- Pick TWO different datasets from the Hugging Face Hub that we did **not** use in the lesson.\n",
        "  Suggested options: `imdb`, `yelp_polarity`, `dbpedia_14`, `rotten_tomatoes`, `trec`.\n",
        "- For each dataset: create Zipf plots for two non-overlapping subsets (keep sizes equal).\n",
        "- For each dataset: print top-10 tokens for each subset and note 2 differences.\n",
        "- For each dataset: compute type/token ratio for each subset and compare.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c720f87",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}